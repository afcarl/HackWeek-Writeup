\section*{Audience and Participant Selection}

A thoughtful robust, and effective participant selection procedure is of crucial importance to the success of a hack week and may require both careful engineering and an in-depth discussion among the organizers.
At conferences, researchers typically report recent results to the community and network with other scientists, largely from their discipline.
In contrast, traditional summer schools aim for senior researchers to transfer knowledge about a particular subject or field to novice researchers, primarily graduate students and early postdoctoral fellows.
Hack weeks differ from both of these in that knowledge transfer occurs across many levels of seniority and across disciplinary boundaries, as well as novelty of the topics discussed,ranging from established theory to new findings.
In addition, the content is primarily participant-driven, and much of it is generated during the event itself.
This mean that a successful hack week requires participants who are both interested in participation, and also feel comfortable participating in discussions and taking risks.
Participant selection also addresses other objectives of a hack week such as increasing minority participation and gender diversity, knowledge transfer between academia and industry, etc. These factors can also be addressed by thoughtful participant selection.
To meet these goals, a thoughtful participant selection process needs to be as transparent to the applicants as possible, and the organizing committee should be held accountable for their performance in selecting participants.
Transparency is necessary for applicants to understand acceptance/rejection decisions, and accountability is of crucial importance for the detection of inherent biases in the selection, which may harm both the event's success as well as the larger community.
One way to maximize transparency in the selection process is to remove the human element from the decision making as far as possible and transfer some of these tasks to a well-designed algorithm.
In this context, well-designed means \cite{o2017weapons}: (1) interpretable, i.e. the algorithm, its parameters and outputs can be understood by humans, (2) openly available, and thus the decision process can be inspected, (3) the algorithm itself does not perpetuate intrinsic biases in the data (though we will show below that an algorithm itself does not entirely remove the requirement of humans to be aware of their biases).
In practice, most selection procedures follow two separate steps. In the first step, the merit of a candidate must be assessed: does the candidate fulfill the requirements posed by the goals of the workshop?
This first step is difficult to automate, because it requires judgment calls, often based on long-form answers.
To avoid implicit/unconcsious bias, in the past, we have sometimes performed this step by blinding ourselves to a candidate's other attributes (including name and other personal information), and assess their candidacy based solely upon key questions asked specifically for this purpose.
When doing this procedure for a large enough sample, it is unlikely that the resulting pool of acceptable candidates is smaller than the number of available spaces at the workshop.
The second step in the selection procedure then requires tie-breaking between equally acceptable candidates.
It is here where one may impose outside constraints on the selection based on the goals of the workshop.
If multiple competing constraints are considered, this task essentially becomes a complex optimization problem, for which algorithms exist that will outperform any human selection procedure.

One solution to this optimization procedure is implemented in the software \textit{entrofy}\footnote{\url{http://github.com/dhuppenkothen/entrofy}}. The algorithm aims to find a group of participants that together match as closely as possible a requested distribution on specified dimensions (e.g., career stage, geographic location, etc.), to meet pre-set fractions set by the organizers.
For example, organizers may require that half of the participants (or as close as possible to that) be graduate students, while also maximizing the number of different countries from which participants originate.
It is worth noting that this algorithm is vulnerable toward biases in two ways: firstly, humans will set the target fractions for any category of interest.
If these targets reproduce the distribution of the overall sample of candidates, the selection will become essentially random.
Any human biases involved in setting these target fractions will be perpetuated in the selection procedure.
Secondly, perhaps more obviously, the algorithm can only act on information that has been collected.
Biased participant sets may still result from selection procedures that fail to include crucial categories. For example, it would be difficult to produce a student-heavy participant set for a summer school if the algorithm has no information about academic seniority, and impossible to correct gender bias in the pool of applicants, if no information is available about the gender of participants.
