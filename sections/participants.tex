\section*{Audience and Participant Selection}

Because hack weeks are at their core non-traditional workshops, it is worth thinking in detail about the target audience for a hack week, along with methods to select an appropriate group of participants. Here, appropriate essentially refers to 'most likely to achieve the stated goal of the hack week', though measuring that achievement remains a difficult issue itself.
This is especially important because hack weeks are very participant-driven workshops.
%At a traditional conference or summer school, the program will be largely set in advance by the organizing committee using the careful selection of speakers and lecturers.
%At a hack week much of the program is in flux both before and during the workshop.
In this context, a successful hack week requires participants who are both interested in participation and feel comfortable participating in discussions and taking risks.
Therefore, a robust, effective participant selection procedure is of crucial importance to the outcomes of the hack week and may require both careful engineering and an in-depth discussion among the organizers.

Perhaps unsurprisingly, the target audience for a hack week depends directly on the stated goal of the workshop.
At conferences, researchers typically report recent results to the community and network with other scientists largely from their discipline, leading to a fairly narrow target distribution in academic seniority and represented fields.
At a summer school, the aim is generally for senior researchers to transfer knowledge about a particular subject or field to novice researchers, primarily graduate students and early postdoctoral fellows.
Hack weeks differ in that knowledge transfer occurs across many levels of seniority, due to the relative newness of the content and the distributed knowledge base.
%Because the potential for knowledge transfer and community building is highest when the group is heterogeneous, participant diverse in both academic background and geographic location should be selected.
%This increases the chances that participants will take their newfound knowledge into their respective communities and spread it further.

Aside from these broad considerations, the tuning of the audience and participant selection will depend directly on several of the axes described in detail above.
In particular, education-focused workshops might be more homogeneous than project-focused workshops, and similarly single-discipline hack weeks may be more homogeneous than interdisciplinary ones.
Additional goals may be not directly related to the workshop itself, but on higher-order goals (e.g.\ increasing minority participation, knowledge transfer between academia and industry) that a community might find desirable and that can be directly addressed by engineering the participant selection.
% For example, women are still a small minority in computational astrophysics.
%One goal of a hack week could be to increase the participation of gender minorities in computation-focused research.
%Similarly, if a particular sub-field within a discipline is ahead of others in their computational approaches, it might be worthwhile to engineer the mix of participants such that a number of experts from that sub-field are present.
%One interesting axis to consider is the mix of academics versus participants from industry.
%The latter may often be more focused on practically useful applications of methods and data sets, and can therefore provide an important counterpoint to more theory-focused academics.
%In particular in fields where the career path from academia to industry is less immediately obvious (as this the case e.g. in astronomy, where little directly relevant industry exists), inviting back participants who transitioned to industry successfully can provide important role models and networking opportunities for junior participants.
%Finally, with much of data science currently performed in the private sector, industry participants can bring directly relevant knowledge and new scientific approaches to the table.

The need to carefully select participants dovetails with another requirement: transparency.
%Up to date, all hack weeks we have organized have been oversubscribed by at least a factor of two, and thus necessarily require turning applicants away.
The selection procedure should be as transparent to the applicants as possible, and the organizing committee should be held accountable for their performance.
Transparency is necessary for applicants to understand acceptance/rejection decisions, and accountability is of crucial importance for the detection of inherent biases in the selection, which may harm both the workshop's success as well as the larger community.

In order to maximize transparency in our selection process we are working to remove the human element from the decision making as far as possible and transfer some of these tasks to a well-designed algorithm.
Here, well-designed refers to several properties: (1) it is interpretable, i.e. the algorithm, its parameters and outputs can be understood by humans, (2) it is openly available, and thus the decision process can be inspected, (3) the algorithm itself does not perpetuate intrinsic biases in the data (though we will show below that an algorithm itself does not entirely remove the requirement of humans to be aware of their biases).

In practice, most selection procedures follow two separate steps, though in the case of human committees, these steps are often conflated.
In the first step, the merit of a candidate must be assessed: does the candidate fulfill the requirements posed by the goals of the workshop? %For example, at Astro Hack Week, it may be unrealistic to admit an undergraduate student in biochemistry, unless they had a compelling reason for attending.
This first step is difficult to automate, because it requires judgment calls, often based on long-form answers.
In the past, we have performed this step by blinding ourselves to a candidate's other attributes (including name and other personal information), and assess their candidacy based solely upon key questions asked specifically for this purpose.
When doing this procedure for a large enough sample, it is unlikely that the resulting pool of acceptable candidates is smaller than the number of available spaces at the workshop.
The second step in the selection procedure thus requires tie-breaking between equally acceptable candidates.
It is here where one may impose outside constraints on the selection based on the goals of the workshop.
If multiple competing constraints are considered, this task essentially becomes a complex optimization problem, for which algorithms exist that will outperform any human selection procedure.

In particular, the software \textit{entrofy}\footnote{\url{http://github.com/dhuppenkothen/entrofy}} employs one such algorithm and is capable of efficient selection of an optimal candidate set based on human target fractions.
It is worth noting that this algorithm is vulnerable toward biases in two ways: firstly, humans will set the target fractions for any category of interest.
If these targets reproduce the distribution of the overall sample of candidates, the selection will become essentially random.
Any human biases involved in setting these target fractions will be perpetuated in the selection procedure.
Secondly, perhaps more obviously, the algorithm can only act on information that has been collected.
Biased participant sets may still result from selection procedures that fail to include crucial categories (for example, it would be difficult to produce a student-heavy participant set for a summer school if the algorithm has no information about academic seniority).

%Within our hack weeks the goal of the selection procedure has always been diversity among several axes.
%This includes academic subdiscipline, to allow for maximally possible knowledge exchange between different domain fields, as well as with researchers from adjacent fields including statistics, computer science and data science.
%Other important categories revolve around the participants' previous knowledge in terms of machine learning, statistics and programming.
%Unlike for a summer school, we have generally selected for a diverse set of participants in order to be able to efficiently pair up novices and experts in projects.
%Finally, we also include demographic information with two main goals: firstly, representation has been proven to be an effective way to foster an inclusive environment where minority participants feel comfortable to participate and take risks.
%Secondly, we would like to boost the participation of minority researchers in computational astrophysics, and our hack week model provides a useful framework for doing so.
